{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "rpath = os.path.abspath('..')\n",
    "if rpath not in sys.path:\n",
    "    sys.path.insert(0, rpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate_helper import setup_weaviate_interface_async, setup_weaviate_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/misge/Documents/Projects/tenx/Teammate/team-mate', '/home/misge/Documents/Projects/tenx/Teammate/team-mate/RAG', '/home/misge/miniconda3/lib/python311.zip', '/home/misge/miniconda3/lib/python3.11', '/home/misge/miniconda3/lib/python3.11/lib-dynload', '', '/home/misge/Documents/Projects/tenx/Teammate/team-mate/.venv/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate_helper import setup_weaviate_interface_async\n",
    "import asyncio\n",
    "\n",
    "async def get_weaviate_interface():\n",
    "    weaviate_interface = await setup_weaviate_interface_async()\n",
    "    return weaviate_interface\n",
    "\n",
    "async def main():\n",
    "    weaviate_interface = setup_weaviate_interface()\n",
    "    interface = await get_weaviate_interface()\n",
    "    return interface \n",
    "\n",
    "interface = await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': [{'class': 'Document',\n",
       "   'description': 'A document class to store documents used for knowledge base',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'The title of the document',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'title',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'The entire content of the document',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'content',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['int'],\n",
       "     'description': 'The word count of the content',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'name': 'wordCount'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'The URL of the document',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'url',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'none'},\n",
       "  {'class': 'DocumentChunk',\n",
       "   'description': 'Chunks of Documentations',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['Document'],\n",
       "     'description': 'Reference to document',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'document'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Content of the chunk',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'text',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Document name',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'doc_name',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'DocumentChunkReference',\n",
       "   'description': 'Links DocumentChunk that was used for a Response',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['DocumentChunk'],\n",
       "     'description': 'Linked DocumentChunk',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'document'},\n",
       "    {'dataType': ['Response'],\n",
       "     'description': 'The chatbot response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'response'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'ResponseReference',\n",
       "   'description': 'Links previous Response that was used for a Response as an example response',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['Response'],\n",
       "     'description': 'The chatbot response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'response'},\n",
       "    {'dataType': ['Response'],\n",
       "     'description': 'The referenced chatbot response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'referenced_response'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'Response',\n",
       "   'description': 'Chatbot responses and associated user prompts',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'User prompt',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'prompt',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Chatbot response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'responseText',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['boolean'],\n",
       "     'description': 'Whether the response was liked',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'liked'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Unique ID of the response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'response_id',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Session ID associated with the response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'session_id',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'Job',\n",
       "   'description': 'Job postings for searching and filtering',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'generative-openai': {'model': 'gpt-3.5-turbo'},\n",
       "    'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': False}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'Title of the job posting',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'title',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Name of the company',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'company',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'JobDescriptionChunk',\n",
       "   'description': \"This property was generated by Weaviate's auto-schema feature on Mon Jun 10 19:38:24 2024\",\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['uuid'],\n",
       "     'description': \"This property was generated by Weaviate's auto-schema feature on Mon Jun 10 19:38:24 2024\",\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'name': 'job_id'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': \"This property was generated by Weaviate's auto-schema feature on Mon Jun 10 19:38:24 2024\",\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'content',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['number'],\n",
       "     'description': \"This property was generated by Weaviate's auto-schema feature on Mon Jun 10 19:38:24 2024\",\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'name': 'order'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'none'}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await interface.client.get_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_info = {\n",
    "    \"class\": \"Job\",\n",
    "    \"description\": \"Job postings for searching and filtering\", \n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"title\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Title of the job posting\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"company\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Name of the company\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"description\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Full job description (optional)\",\n",
    "            \n",
    "        }\n",
    "    ],\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "     \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {\n",
    "            \"vectorizeClassName\": False,\n",
    "            \"model\": \"ada\",\n",
    "            \"modelVersion\": \"002\",\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"generative-openai\": {\n",
    "          \"model\": \"gpt-3.5-turbo\"\n",
    "        }\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "await interface.client.delete_class(class_name=\"Job\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "await interface.client.create_class(class_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': [{'class': 'Document',\n",
       "   'description': 'A document class to store documents used for knowledge base',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'The title of the document',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'title',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'The entire content of the document',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'content',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['int'],\n",
       "     'description': 'The word count of the content',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'name': 'wordCount'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'The URL of the document',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'name': 'url',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'none'},\n",
       "  {'class': 'DocumentChunk',\n",
       "   'description': 'Chunks of Documentations',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['Document'],\n",
       "     'description': 'Reference to document',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'document'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Content of the chunk',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'text',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Document name',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'doc_name',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'DocumentChunkReference',\n",
       "   'description': 'Links DocumentChunk that was used for a Response',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['DocumentChunk'],\n",
       "     'description': 'Linked DocumentChunk',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'document'},\n",
       "    {'dataType': ['Response'],\n",
       "     'description': 'The chatbot response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'response'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'ResponseReference',\n",
       "   'description': 'Links previous Response that was used for a Response as an example response',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['Response'],\n",
       "     'description': 'The chatbot response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'response'},\n",
       "    {'dataType': ['Response'],\n",
       "     'description': 'The referenced chatbot response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'referenced_response'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'Response',\n",
       "   'description': 'Chatbot responses and associated user prompts',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': True}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'User prompt',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'prompt',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Chatbot response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'responseText',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['boolean'],\n",
       "     'description': 'Whether the response was liked',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': False,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'liked'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Unique ID of the response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'response_id',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Session ID associated with the response',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'session_id',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'},\n",
       "  {'class': 'Job',\n",
       "   'description': 'Job postings for searching and filtering',\n",
       "   'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "    'cleanupIntervalSeconds': 60,\n",
       "    'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       "   'moduleConfig': {'generative-openai': {'model': 'gpt-3.5-turbo'},\n",
       "    'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "     'model': 'ada',\n",
       "     'modelVersion': '002',\n",
       "     'type': 'text',\n",
       "     'vectorizeClassName': False}},\n",
       "   'multiTenancyConfig': {'enabled': False},\n",
       "   'properties': [{'dataType': ['text'],\n",
       "     'description': 'Title of the job posting',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'title',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Name of the company',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'company',\n",
       "     'tokenization': 'word'},\n",
       "    {'dataType': ['text'],\n",
       "     'description': 'Full job description (optional)',\n",
       "     'indexFilterable': True,\n",
       "     'indexSearchable': True,\n",
       "     'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "       'vectorizePropertyName': False}},\n",
       "     'name': 'description',\n",
       "     'tokenization': 'word'}],\n",
       "   'replicationConfig': {'factor': 1},\n",
       "   'shardingConfig': {'virtualPerPhysical': 128,\n",
       "    'desiredCount': 1,\n",
       "    'actualCount': 1,\n",
       "    'desiredVirtualCount': 128,\n",
       "    'actualVirtualCount': 128,\n",
       "    'key': '_id',\n",
       "    'strategy': 'hash',\n",
       "    'function': 'murmur3'},\n",
       "   'vectorIndexConfig': {'skip': False,\n",
       "    'cleanupIntervalSeconds': 300,\n",
       "    'maxConnections': 64,\n",
       "    'efConstruction': 128,\n",
       "    'ef': -1,\n",
       "    'dynamicEfMin': 100,\n",
       "    'dynamicEfMax': 500,\n",
       "    'dynamicEfFactor': 8,\n",
       "    'vectorCacheMaxObjects': 1000000000000,\n",
       "    'flatSearchCutoff': 40000,\n",
       "    'distance': 'cosine',\n",
       "    'pq': {'enabled': False,\n",
       "     'bitCompression': False,\n",
       "     'segments': 0,\n",
       "     'centroids': 256,\n",
       "     'trainingLimit': 100000,\n",
       "     'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       "   'vectorIndexType': 'hnsw',\n",
       "   'vectorizer': 'text2vec-openai'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await interface.client.get_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/all_nov_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>company_link</th>\n",
       "      <th>place</th>\n",
       "      <th>date</th>\n",
       "      <th>apply_link</th>\n",
       "      <th>post_link</th>\n",
       "      <th>seniority_level</th>\n",
       "      <th>employmnet_type</th>\n",
       "      <th>description</th>\n",
       "      <th>job_title_id</th>\n",
       "      <th>job_desc_id</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/company/9384440/</td>\n",
       "      <td>Austin, TX Remote</td>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3344976633/...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Description\\n\\n\\n\\n\\nMediavine is seeking a Se...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Software Test Engineer / SDET - (Remote - US)</td>\n",
       "      <td>Mediavine</td>\n",
       "      <td>https://www.linkedin.com/company/71904349/</td>\n",
       "      <td>Phoenix, AZ Remote</td>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3348625106/...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Looking to help with the integration of the Ve...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>Bayes Invest</td>\n",
       "      <td>https://www.linkedin.com/company/71904349/</td>\n",
       "      <td>Detroit, MI Remote</td>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3345440941/...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Looking to help with the integration of the Ve...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AUTOSAR Software Engineer - REMOTE</td>\n",
       "      <td>Actalent</td>\n",
       "      <td>https://www.linkedin.com/company/71904349/</td>\n",
       "      <td>Bothell, WA Remote</td>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>https://jsv3.recruitics.com/redirect?rx_cid=33...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3348618068/...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Embedded Software Engineer - Bothell, WA - Hyb...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AUTOSAR Software Engineer - REMOTE</td>\n",
       "      <td>Actalent</td>\n",
       "      <td>https://www.linkedin.com/company/71904349/</td>\n",
       "      <td>Raleigh, NC Remote</td>\n",
       "      <td>2022-11-06</td>\n",
       "      <td>https://jsv3.recruitics.com/redirect?rx_cid=33...</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/3348614524/...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Description:* Actalent is seeking an Cybersecu...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2                                          title       company  \\\n",
       "0             0                              Software Engineer           NaN   \n",
       "1             1  Software Test Engineer / SDET - (Remote - US)     Mediavine   \n",
       "2             2                              Software Engineer  Bayes Invest   \n",
       "3             3             AUTOSAR Software Engineer - REMOTE      Actalent   \n",
       "4             4             AUTOSAR Software Engineer - REMOTE      Actalent   \n",
       "\n",
       "                                 company_link               place        date  \\\n",
       "0   https://www.linkedin.com/company/9384440/   Austin, TX Remote  2022-11-06   \n",
       "1  https://www.linkedin.com/company/71904349/  Phoenix, AZ Remote  2022-11-06   \n",
       "2  https://www.linkedin.com/company/71904349/  Detroit, MI Remote  2022-11-06   \n",
       "3  https://www.linkedin.com/company/71904349/  Bothell, WA Remote  2022-11-06   \n",
       "4  https://www.linkedin.com/company/71904349/  Raleigh, NC Remote  2022-11-06   \n",
       "\n",
       "                                          apply_link  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  https://jsv3.recruitics.com/redirect?rx_cid=33...   \n",
       "4  https://jsv3.recruitics.com/redirect?rx_cid=33...   \n",
       "\n",
       "                                           post_link seniority_level  \\\n",
       "0  https://www.linkedin.com/jobs/view/3344976633/...     Entry level   \n",
       "1  https://www.linkedin.com/jobs/view/3348625106/...     Entry level   \n",
       "2  https://www.linkedin.com/jobs/view/3345440941/...     Entry level   \n",
       "3  https://www.linkedin.com/jobs/view/3348618068/...     Entry level   \n",
       "4  https://www.linkedin.com/jobs/view/3348614524/...     Entry level   \n",
       "\n",
       "  employmnet_type                                        description  \\\n",
       "0       Full-time  Description\\n\\n\\n\\n\\nMediavine is seeking a Se...   \n",
       "1      Full-time   Looking to help with the integration of the Ve...   \n",
       "2       Full-time  Looking to help with the integration of the Ve...   \n",
       "3      Full-time   Embedded Software Engineer - Bothell, WA - Hyb...   \n",
       "4      Full-time   Description:* Actalent is seeking an Cybersecu...   \n",
       "\n",
       "   job_title_id  job_desc_id  Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \n",
       "0             3            0         NaN           NaN             NaN  \n",
       "1             3            1         NaN           NaN             NaN  \n",
       "2             3            2         NaN           NaN             NaN  \n",
       "3             3            3         NaN           NaN             NaN  \n",
       "4             3            4         NaN           NaN             NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misge/Documents/Projects/tenx/Teammate/team-mate/.venv/lib/python3.11/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL,\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-API-Key\":OPENAI_KEY\n",
    "    }\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misge/Documents/Projects/tenx/Teammate/team-mate/.venv/lib/python3.11/site-packages/weaviate/warnings.py:142: DeprecationWarning: Dep006: You are using the `client.batch()` method. This method will be removed in the next major release.\n",
      "            Use the `client.batch.configure()` method to configure your batch process, and `client.batch` to enter the context manager.\n",
      "\n",
      "            See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "from weaviate_helper import setup_weaviate_interface_async\n",
    "from weaviate.util import generate_uuid5\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "\n",
    "def validate_and_clean_data(row):\n",
    "    for field in ['title', 'company', 'description']:\n",
    "        if pd.isna(row[field]):\n",
    "            row[field] = \"\"\n",
    "    return row\n",
    "\n",
    "async def add_to_batch_with_retry(batch, new_object, max_retries=5, delay=60):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            batch.add_data_object(\n",
    "                new_object,\n",
    "                class_name=\"Job\",\n",
    "                uuid=generate_uuid5(new_object)\n",
    "            )\n",
    "            break \n",
    "        except Exception as e:\n",
    "            if 'rate_limit_exceeded' in str(e).lower():\n",
    "                print(f\"Rate limit exceeded, attempt {attempt + 1}/{max_retries}. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay) \n",
    "            else:\n",
    "                print(f\"Error adding to batch: {e}\")\n",
    "                raise  \n",
    "\n",
    "async def populate_database(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df = df.head(200)\n",
    "    columns_to_keep = ['title', 'company', 'description']\n",
    "    df = df[columns_to_keep]\n",
    "    \n",
    "    df = df.apply(validate_and_clean_data, axis=1)\n",
    "\n",
    "    batch_size = 25\n",
    "    num_workers = 1\n",
    "\n",
    "    with client.batch(\n",
    "        batch_size=batch_size,  \n",
    "        num_workers=num_workers,   \n",
    "    ) as batch:\n",
    "        for _, row in df.iterrows():\n",
    "            new_object = {\n",
    "                \"title\": row.title,\n",
    "                \"company\": row.company,\n",
    "                \"description\": row.description\n",
    "            }\n",
    "            await add_to_batch_with_retry(batch, new_object)\n",
    "            time.sleep(5)\n",
    "            \n",
    "csv_file_path = \"data/all_nov_jobs.csv\"\n",
    "\n",
    "await populate_database(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### populate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misge/Documents/Projects/tenx/Teammate/team-mate/.venv/lib/python3.11/site-packages/weaviate/warnings.py:142: DeprecationWarning: Dep006: You are using the `client.batch()` method. This method will be removed in the next major release.\n",
      "            Use the `client.batch.configure()` method to configure your batch process, and `client.batch` to enter the context manager.\n",
      "\n",
      "            See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: send POST request: Post \"https://api.openai.com/v1/embeddings\": dial tcp: lookup api.openai.com on 127.0.0.11:53: server misbehaving'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n",
      "{'error': [{'message': 'update vector: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number'}]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "from weaviate_helper import setup_weaviate_interface_async\n",
    "from weaviate.util import generate_uuid5\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "\n",
    "def validate_and_clean_data(row):\n",
    "    for field in ['title', 'company', 'description']:\n",
    "        if pd.isna(row[field]):\n",
    "            row[field] = \"\"\n",
    "    return row\n",
    "\n",
    "async def populate_database(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df = df.head(200)\n",
    "    columns_to_keep = ['title', 'company', 'description']\n",
    "    df = df[columns_to_keep]\n",
    "    \n",
    "    df = df.apply(validate_and_clean_data, axis=1)\n",
    "\n",
    "    batch_size = 200\n",
    "    num_workers = 2\n",
    "\n",
    "    with client.batch(\n",
    "        batch_size=batch_size,  \n",
    "        num_workers=num_workers,   \n",
    "    ) as batch:\n",
    "        for _, row in df.iterrows():\n",
    "            new_object = {\n",
    "                \"title\": row.title,\n",
    "                \"company\": row.company,\n",
    "                \"description\": row.description\n",
    "            }\n",
    "            batch.add_data_object(\n",
    "                new_object,\n",
    "                class_name=\"Job\",\n",
    "                uuid=generate_uuid5(new_object)\n",
    "            )\n",
    "            \n",
    "csv_file_path = \"data/all_nov_jobs.csv\"\n",
    "\n",
    "await populate_database(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Aggregate': {'Job': [{'meta': {'count': 1}}]}}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query.aggregate(\"Job\").with_meta_count().do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misge/miniconda3/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=69 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "An error occurred while creating batch objects: \n",
      "Batch creation faild\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "from weaviate_helper import setup_weaviate_interface_async\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "async def get_weaviate_interface():\n",
    "    weaviate_interface = await setup_weaviate_interface_async()\n",
    "    return weaviate_interface\n",
    "\n",
    "def validate_and_clean_data(row):\n",
    "    for field in ['title', 'company', 'description']:\n",
    "        if pd.isna(row[field]):\n",
    "            row[field] = \"\"\n",
    "    return row\n",
    "\n",
    "async def populate_database(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    columns_to_keep = ['title', 'company', 'description']\n",
    "    df = df[columns_to_keep]\n",
    "    \n",
    "    df = df.apply(validate_and_clean_data, axis=1)\n",
    "    interface = await get_weaviate_interface()\n",
    "    \n",
    "    objects = []\n",
    "    for _, row in df.iterrows():\n",
    "        new_object = {\n",
    "            \"title\": row.title,\n",
    "            \"company\": row.company,\n",
    "            \"description\": row.description\n",
    "        }\n",
    "        objects.append(new_object)\n",
    "    \n",
    "    batch_size = 200\n",
    "    \n",
    "    for i in range(0, len(objects), batch_size):\n",
    "        batch = objects[i:i+batch_size]\n",
    "        try:\n",
    "            success = await interface.client.batch_create_objects(batch, class_name=\"Job\")\n",
    "            if success:\n",
    "                print(\"Batch created successfully\")\n",
    "            else:\n",
    "                print(\"Batch creation faild\")\n",
    "      \n",
    "        except httpx.HTTPStatusError as e:\n",
    "            print(f\"HTTP error occurred: {e.response.status_code} - {e.response.text}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while creating batch objects: {e}\")\n",
    "\n",
    "csv_file_path = \"data/all_nov_jobs.csv\"\n",
    "\n",
    "await populate_database(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misge/Documents/Projects/tenx/Teammate/team-mate/.venv/lib/python3.11/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': {'Aggregate': {'Job': [{'meta': {'count': 1}}]}}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL,\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-API-Key\":OPENAI_KEY\n",
    "    }\n",
    ")  \n",
    "\n",
    "client.query.aggregate(\"Job\").with_meta_count().do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misge/Documents/Projects/tenx/Teammate/team-mate/.venv/lib/python3.11/site-packages/weaviate/warnings.py:162: DeprecationWarning: Dep016: Python client v3 `weaviate.Client(...)` connections and methods are deprecated. Update\n",
      "            your code to use Python client v4 `weaviate.WeaviateClient` connections and methods.\n",
      "\n",
      "            For Python Client v4 usage, see: https://weaviate.io/developers/weaviate/client-libraries/python\n",
      "            For code migration, see: https://weaviate.io/developers/weaviate/client-libraries/python/v3_v4_migration\n",
      "            \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Get': {'Job': None}}, 'errors': [{'locations': [{'column': 6, 'line': 1}], 'message': 'explorer: get class: vectorize params: vectorize params: vectorize params: vectorize keywords: remote client vectorize: unmarshal response body: json: invalid number literal, trying to unmarshal \"\\\\\"rate_limit_exceeded\\\\\"\" into Number', 'path': ['Get', 'Job']}]}\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import os\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = weaviate.Client(\n",
    "    url=WEAVIATE_URL,\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-API-Key\":OPENAI_KEY\n",
    "    }\n",
    ")  \n",
    "\n",
    "response = (\n",
    "    client.query\n",
    "    .get(\"Job\", [\"title\", \"company\", \"description\"])\n",
    "    .with_near_text({\n",
    "        \"concepts\": \"software engineer\"\n",
    "    })\n",
    "    .with_limit(10)\n",
    "    .with_additional([\"distance\"])\n",
    "    .do()\n",
    ")\n",
    "\n",
    "print(response)\n",
    "# Print the results\n",
    "# for result in response['data']['Get']['Job']:\n",
    "#     print(f\"Title: {result['title']}\")\n",
    "#     print(f\"Company: {result['company']}\")\n",
    "#     print(f\"Company Link: {result['company_link']}\")\n",
    "#     print(f\"Place: {result['place']}\")\n",
    "#     print(f\"Date: {result['date']}\")\n",
    "#     print(f\"Apply Link: {result['apply_link']}\")\n",
    "#     print(f\"Description: {result['description']}\")\n",
    "#     print(f\"Distance: {result['_additional']['distance']}\")\n",
    "#     print(\"----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Client' object has no attribute 'collections'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mweaviate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclasses\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetadataQuery\n\u001b[1;32m      5\u001b[0m client \u001b[38;5;241m=\u001b[39m weaviate\u001b[38;5;241m.\u001b[39mClient(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://localhost:8080\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1.23.7\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m job_collection \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollections\u001b[49m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m response \u001b[38;5;241m=\u001b[39m job_collection\u001b[38;5;241m.\u001b[39mgenerate\u001b[38;5;241m.\u001b[39mnear_text(\n\u001b[1;32m     10\u001b[0m     query\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote software engineer positions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     12\u001b[0m     return_metadata\u001b[38;5;241m=\u001b[39mMetadataQuery(distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mobjects:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'collections'"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "import os\n",
    "from weaviate.classes.query import MetadataQuery\n",
    "\n",
    "client = weaviate.Client(\n",
    "    url=\"http://localhost:8080\", \"v1.23.7\",\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-API-Key\":OPENAI_API_KEY\n",
    "    }\n",
    "    )\n",
    "\n",
    "job_collection = client.collections.get(\"Job\")\n",
    "\n",
    "response = job_collection.generate.near_text(\n",
    "    query=\"Remote software engineer positions\",\n",
    "    limit=10,\n",
    "    return_metadata=MetadataQuery(distance=True)\n",
    ")\n",
    "\n",
    "for o in response.objects:\n",
    "    print(o.properties)\n",
    "    print(o.metadata.distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6.4\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "print(weaviate.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_weaviate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemote software engineer positions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[43msearch_weaviate\u001b[49m(query)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Company: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompany\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Place: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplace\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search_weaviate' is not defined"
     ]
    }
   ],
   "source": [
    "query = \"Remote software engineer positions\"\n",
    "results = await search_weaviate(query)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Title: {result['title']}, Company: {result['company']}, Place: {result['place']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.util import generate_uuid5\n",
    "import weaviate\n",
    "\n",
    "client = weaviate.connect_to_local()\n",
    "\n",
    "def validate_and_clean_data(row):\n",
    "    if not isinstance(row['date'], str):\n",
    "        row['date'] = str(row['date'])\n",
    "    for field in ['title', 'company', 'company_link', 'place', 'date', 'apply_link', 'description']:\n",
    "        if pd.isna(row[field]):\n",
    "            row[field] = \"\"\n",
    "    return row\n",
    "\n",
    "columns_to_keep = ['title', 'company', 'company_link', 'place', 'date', 'apply_link', 'description']\n",
    "df = df[columns_to_keep]\n",
    "\n",
    "df = df.apply(validate_and_clean_data, axis=1)\n",
    "\n",
    "with client.batch(\n",
    "    batch_size=200,\n",
    "    num_workers=2,\n",
    ") as batch:\n",
    "    for _, row in df.iterrows():\n",
    "        new_object = {\n",
    "            \"title\": row.title,\n",
    "            \"company\": row.company,\n",
    "            \"company_link\": row.company_link,\n",
    "            \"place\": row.place,\n",
    "            \"date\": row.date,\n",
    "            \"apply_link\": row.apply_link,\n",
    "            \"description\": row.description\n",
    "        }\n",
    "        batch.add_data_object(\n",
    "            new_object,\n",
    "            class_name=\"Job\",\n",
    "            uuid=generate_uuid5(question_object)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_info = {\n",
    "    \"class\": \"Job\",\n",
    "    \"description\": \"Job postings for searching and filtering\", \n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"title\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Title of the job posting\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"company\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Name of the company\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "     \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {\n",
    "            \"vectorizeClassName\": False,\n",
    "            \"model\": \"ada\",\n",
    "            \"modelVersion\": \"002\",\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"generative-openai\": {\n",
    "          \"model\": \"gpt-3.5-turbo\"\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "chunk_info = {\n",
    "    \"class\": \"JobDescriptionChunk\",\n",
    "    \"description\": \"Chunks of job descriptions linked to job postings\", \n",
    "    \"properties\": [\n",
    "        {\n",
    "            \"name\": \"job_id\",\n",
    "            \"dataType\": [\"uuid\"],\n",
    "            \"description\": \"Reference to the job posting\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"content\",\n",
    "            \"dataType\": [\"text\"],\n",
    "            \"description\": \"Chunk of the job description\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"order\",\n",
    "            \"dataType\": [\"int\"],\n",
    "            \"description\": \"Order of the chunk in the full description\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "    \"moduleConfig\": {\n",
    "        \"text2vec-openai\": {\n",
    "            \"vectorizeClassName\": False,\n",
    "            \"model\": \"ada\",\n",
    "            \"modelVersion\": \"002\",\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        \"generative-openai\": {\n",
    "            \"model\": \"gpt-3.5-turbo\"\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "await interface.client.delete_class(class_name=\"Job\")\n",
    "await interface.client.create_class(class_info)\n",
    "await interface.client.delete_class(class_name=\"JobDescriptionChunk\")\n",
    "await interface.client.create_class(chunk_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/misge/miniconda3/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=69 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/misge/miniconda3/lib/python3.11/asyncio/selector_events.py:864: ResourceWarning: unclosed transport <_SelectorSocketTransport fd=66 read=idle write=<idle, bufsize=0>>\n",
      "  _warn(f\"unclosed transport {self!r}\", ResourceWarning, source=self)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'WeaviateInterface' object does not support the asynchronous context manager protocol",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 84\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch create objects process completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/all_nov_jobs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m populate_database(csv_file_path)\n",
      "Cell \u001b[0;32mIn[43], line 29\u001b[0m, in \u001b[0;36mpopulate_database\u001b[0;34m(csv_file_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(validate_and_clean_data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m inteface \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_weaviate_interface()\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m interface:\n\u001b[1;32m     30\u001b[0m     objects \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: 'WeaviateInterface' object does not support the asynchronous context manager protocol"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "import asyncio\n",
    "from weaviate_helper import setup_weaviate_interface_async\n",
    "import httpx\n",
    "from uuid import uuid4\n",
    "\n",
    "CHUNK_SIZE = 500  # Define the maximum length for each chunk\n",
    "\n",
    "async def get_weaviate_interface():\n",
    "    return await setup_weaviate_interface()\n",
    "\n",
    "def validate_and_clean_data(row: pd.Series) -> pd.Series:\n",
    "    for field in ['title', 'company', 'description']:\n",
    "        if pd.isna(row[field]):\n",
    "            row[field] = \"\"\n",
    "    return row\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int) -> List[str]:\n",
    "    return [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "async def populate_database(csv_file_path: str) -> None:\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    columns_to_keep = ['title', 'company', 'description']\n",
    "    df = df[columns_to_keep]\n",
    "    df = df.apply(validate_and_clean_data, axis=1)\n",
    "    \n",
    "    inteface = await get_weaviate_interface()\n",
    "    async with interface:\n",
    "        objects = []\n",
    "        chunks = []\n",
    "        for _, row in df.iterrows():\n",
    "            job_id = str(uuid4())\n",
    "            new_object = {\n",
    "                \"id\": job_id,\n",
    "                \"title\": row.title,\n",
    "                \"company\": row.company\n",
    "            }\n",
    "            objects.append(new_object)\n",
    "            \n",
    "            description_chunks = chunk_text(row.description, CHUNK_SIZE)\n",
    "            for order, chunk in enumerate(description_chunks):\n",
    "                chunk_object = {\n",
    "                    \"job_id\": job_id,\n",
    "                    \"content\": chunk,\n",
    "                    \"order\": order\n",
    "                }\n",
    "                chunks.append(chunk_object)\n",
    "    \n",
    "        batch_size = 200\n",
    "        \n",
    "        for i in range(0, len(objects), batch_size):\n",
    "            batch = objects[i:i+batch_size]\n",
    "            try:\n",
    "                success = await interface.client.batch_create_objects(batch, class_name=\"Job\")\n",
    "                if success:\n",
    "                    print(f\"Job batch {i//batch_size + 1} created successfully\")\n",
    "                else:\n",
    "                    print(f\"Job batch {i//batch_size + 1} creation failed\")\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                print(f\"HTTP error occurred: {e.response.status_code} - {e.response.text}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while creating job batch objects: {e}\")\n",
    "    \n",
    "        for i in range(0, len(chunks), batch_size):\n",
    "            batch = chunks[i:i+batch_size]\n",
    "            try:\n",
    "                success = await interface.client.batch_create_objects(batch, class_name=\"JobDescriptionChunk\")\n",
    "                if success:\n",
    "                    print(f\"Chunk batch {i//batch_size + 1} created successfully\")\n",
    "                else:\n",
    "                    print(f\"Chunk batch {i//batch_size + 1} creation failed\")\n",
    "            except httpx.HTTPStatusError as e:\n",
    "                print(f\"HTTP error occurred: {e.response.status_code} - {e.response.text}\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while creating chunk batch objects: {e}\")\n",
    "\n",
    "        print(\"Batch create objects process completed\")\n",
    "\n",
    "csv_file_path = \"data/all_nov_jobs.csv\"\n",
    "\n",
    "await populate_database(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
